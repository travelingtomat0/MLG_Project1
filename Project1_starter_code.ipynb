{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are required to run your project\n",
    "# You are allowed to add more libraries as you need\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gene_name', 'chr', 'gene_start', 'gene_end', 'TSS_start', 'TSS_end',\n",
      "       'strand'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# TODO: \n",
    "# Load your feature (bed and/or bigwig and/or fasta) and target files (tsv) here.\n",
    "# Decide which features to use for training. Feel free to process them however you need.\n",
    "\n",
    "from utils.dataset import InputDataset\n",
    "\n",
    "# NOTE: \n",
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you. \n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "#phils_path = \"/home/phil/Downloads/ML4G_Project_1_Data\"\n",
    "\n",
    "path_data = \"/home/phil/Downloads/ML4G_Project_1_Data\"  # TODO\n",
    "path_test = \"/path/to/test/info/file\"   # X3_test_info.tsv ; TODO\n",
    "path_test = os.path.join(path_data, 'CAGE-train/CAGE-train/X3_test_info.tsv')\n",
    "test_genes = pd.read_csv(path_test, sep='\\t')\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "# load gene information\n",
    "train_info_X1 = pd.read_csv(os.path.join(path_data, 'CAGE-train', 'CAGE-train', 'X1_train_info.tsv'), sep='\\t')\n",
    "train_info_X2 = pd.read_csv(os.path.join(path_data, 'CAGE-train', 'CAGE-train', 'X1_train_info.tsv'), sep='\\t')\n",
    "print(f'Training Data Keys: {train_info_X1.keys()}')\n",
    "\n",
    "# Modalities chosen by looking at the\n",
    "modalities = ['DNase', 'H3K27ac', 'H3K4me1', 'H3K4me3', 'H3K36me3']\n",
    "window_size = 20000\n",
    "\n",
    "# load_data\n",
    "train_data_X1 = InputDataset(data_directory=path_data, cell_line='X1', objective=\"train\", modality_names=modalities, window_size=window_size)\n",
    "\n",
    "val_data_X1 = InputDataset(data_directory=path_data, cell_line='X1', objective=\"val\", modality_names=modalities, window_size=window_size)\n",
    "\n",
    "train_data_X2 = InputDataset(data_directory=path_data, cell_line='X2', objective=\"train\", modality_names=modalities, window_size=window_size)\n",
    "\n",
    "val_data_X2 = InputDataset(data_directory=path_data, cell_line='X2', objective=\"val\", modality_names=modalities, window_size=window_size)\n",
    "\n",
    "# ---------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Select the best model to predict gene expression from the obtained features in WP 1.1.\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from utils.lightning_wrapper import ModelWrapper\n",
    "from models.neural_nets import ConvolutionalModel\n",
    "\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "# Subsetting method to use less data while testing models:\n",
    "stepsize = 100\n",
    "data_indices = list(range(0, len(train_data_X1), stepsize))\n",
    "train_data_X1 = torch.utils.data.Subset(train_data_X1, data_indices)\n",
    "\n",
    "data_indices = list(range(0, len(val_data_X1), stepsize))\n",
    "val_data_X1 = torch.utils.data.Subset(val_data_X1, data_indices)\n",
    "\n",
    "# TODO: in case we use the sequence as additional information, then add 4 to the number of channels c.\n",
    "model = ConvolutionalModel(c=2*len(modalities))\n",
    "\n",
    "lightning_model = ModelWrapper(model_architecture=model, learning_rate=1e-3, loss=torch.nn.L1Loss, datasets=[train_data_X1, val_data_X1], batch_size=1)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, deterministic=True, reload_dataloaders_every_n_epochs=5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    trainer.fit(lightning_model, accelerator=\"gpu\")\n",
    "else:\n",
    "    trainer.fit(lightning_model)\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Using the model trained in WP 1.2, make predictions on the test data (chr 1 of cell line X3).\n",
    "# Store predictions in a variable called \"pred\" which is a numpy array.\n",
    "\n",
    "pred = None\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'path/to/save/output/file'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"LastName_FirstName_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes['gex_predicted'] = pred.tolist()\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}